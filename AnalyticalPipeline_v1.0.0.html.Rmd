---
title: "Step-by-step testing of wearable sleep technology"
author: "Luca Menghini"
date: "January 15th 2020"
output:
  html_document:
    df_print: paged
    toc: true
    toc_float: true
  pdf_document: default
  word_document: default
  theme: united
  toc: true # table of content true
---

```{r setup, echo=TRUE,warning=FALSE,message=FALSE}

```

<br>

# 1. Aims and content

<br>

The main goal of following analyses is to describe the accuracy of the **Fitbit Charge 2 (FC2)** in measuring sleep stages and metrics on a sample of *14 healthy adults (6 F)* over a total number of 27 nights. More specifically, the analyses aim at:

- assessing the FC2 overall accuracy compared to polisomnography (PSG), 

- comparing the **"standard"** FC2 classification system with a recent advancement (**"short wakes", SW**) that is supposed to correct wrongly detected “light” epochs when short awakenings (i.e., less than 180 seconds) are detected,

- evaluating the effect of alcohol comsumption on the discrepancies between FC2 and PSG, with the hypotesis to observe higher discrepancies during nights when participants' consumed alcohol compared to nights with no alcohol consumption.

The following procedures include an **epoch-by-epoch (EBE) analysis** to assess the FC2 accuracy in detecting sleep stages (i.e., wake, light, sleep, and REM sleep), and a **Bland-Altman (BA) analysis** to assess the agreement between FC2- and PSG-derived sleep metrics (i.e., total sleep time, TST; sleep efficiency, SE; sleep onset latency, SOL; wake after sleep onset, SOL). 

<br>

The document is structured as follows:

1. the dataset is **loaded and encoded**: (a) each EBE raw data file is loaded to be included in a single dataset, (b) a subject-by-subject check is performed to assess discrepancies between the "standard" sleep classification and the SW update, (c) the files with *sleep metrics* raw data are also loaded and encoded in a single dataset.

2. An **EBE analysis** is performed on both the "standard" and the SW sleep classifications system compared to PSG, with the aim to assess if and how much the "new" system increases the measurement accuracy. If the WS is more accurate than the "standard" one, the former will be considered in the following steps. Otherwhise, the "standard" system will be considered.

3. A **BA analysis** is performed to assess the agreement between FC2-derived sleep metrics with those collected by the PSG.

4. The effects of **alcohol consumption** on the systematic bias observed in FC2- compared to PSG-derived sleep metrics is assessed graphically and through non-parametric statistical tests.

<br>

# 2. Data Structure  {.tabset .tabset-fade .tabset-pills}

<br>

Here, the datasets are **loaded and encoded**. First, each *EBE raw data file* is loaded to be included in a single dataset. Then, the files are checked to *assess the discrepancies* between the "standard" and the "short wakes" (SW) sleep classification system. Finally, the files with *sleep metrics* are loaded and encoded in a single dataset. A data dictionary explaining the two dataset is available in the last section.

<br>

```{r warning=FALSE,message=FALSE}

library(readxl) # required package to read xlsx

```

<br>

### EBE FILES

<br>

As a first step, we load the **epoch-by-epoch raw data files**. Each file is associated to a sigle night on a given participant.

<br>

```{r warning=FALSE,message=FALSE}

rm(list=ls())

# read all file names in the data.path folder
data.path <- "IndividualEpochComparisons"
paths = list.files(data.path, recursive = TRUE,full.names = TRUE, include.dirs = FALSE)

# create empty dataset where the data will be stored
ebe <- data.frame(id=NA,night=NA,Alcohol=NA,Classic_FB=NA,New_FB=NA,PSG=NA)

# load data into the dataset
for(path in paths){
  new.data <- read_excel(path) # load the file
                              # take ID, night number and alcohol condition from the file name
  ebe <- rbind(ebe,data.frame(id=substr(gsub("/","",gsub(data.path,"",path)),start=1,stop=5),
                              night=substr(gsub("/","",gsub(data.path,"",path)),start=12,stop=12),
                              Alcohol=substr(gsub("/","",gsub(data.path,"",path)),start=14,stop=14),
                              new.data))
}
ebe <- ebe[2:nrow(ebe),] # remove first row (empty)
ebe

```

<br>

We created the **ebe** dataset, including the epoch-by-epoch data of all nights in all participants. The dataset includes participant's **ID**, the **night** number, the **alcohol condition**, and the sleep scoring performed using the "standard" FC2 (**Classic_FB**) classification system, the SW update (**New_FB**), and the **PSG**-derived scoring.

Then, we create a new variable ("epoch") that counts the epochs per each night and each participant.

<br>

```{r warning=FALSE,message=FALSE}

ebe <- plyr::ddply(ebe,c("id","night"),transform,epoch=seq_along(night))
ebe

```

<br>

We can use this information for computing the **average time in bed (TIB)** in our sample. Since each epoch lasts 30 seconds, we can obtain the number of minutes spent in bed by dividing the number of epochs in each participant-night couple by 2. By dividing this result by 60, we can obtain the number of hours spent in bed.

<br>

```{r warning=FALSE,message=FALSE}

IDs <- levels(as.factor(ebe$id))
NIGHTs <- levels(as.factor(ebe$night))
epochs <- data.frame(matrix(nrow=0,ncol=3)) # empty dataset to be filled with night durations
for(ID in IDs){ for(NIGHT in NIGHTs){
    if(nrow(ebe[ebe$id==ID&ebe$night==NIGHT,])!=0){
      epochs <- rbind(epochs,data.frame(id=ID,night=NIGHT,TIB=max(ebe[ebe$id==ID&ebe$night==NIGHT,"epoch"])))
    }           
  }
}
epochs

hist(epochs$TIB/2/60,main="Time in bed",xlab="TIB (hours)")
round(mean(epochs$TIB/2/60),2) # mean TIB (hours)
round(sd(epochs$TIB/2/60),2) # sd TIB (hours)

```

<br>

*Comments:*

- The histogram shows that most night lasted more than 6 hours, whereas one night (night 4 in participant AA036) lasted only 3 hours and 15 minutes.

- On average, our participants slept 6:08 hours (SD = 1:13).

<br>

One last step consists in recoding cases of wrongly scored PSG epochs: 

- values **13** in the PSG column (44 cases) mean "unsure" (due to technical problems resulting in PSG recording freezing for short bouts of time). These epochs are discarded,

- values **0** in the PSG columns (2 cases) mean "missing". In these two cases, the values are recoded as REM sleep (5).

<br>

```{r warning=FALSE,message=FALSE}

nrow(ebe[ebe$PSG==13,]) # number of rows with value 13
ebe <- ebe[ebe$PSG!=13,] # discarting those cases

nrow(ebe[ebe$PSG==0,]) # number of rows with PSG value 0
ebe[ebe$PSG==0,"PSG"] <- 5 # changing 0 into REM sleep

nrow(ebe) # final number of considered epochs

```

<br>

The final dataset consists of 20,558 30-second epochs.

<br>

### FC2 "STANDARD" vs. "SHORT WAKES"

<br>

A first check is performed to evaluate the discrepancies between the "standard" FC2 classification system and the "short wakes" (SW) update.

According to the Fitabase data dictionary (p.20, consulted from www.fitabase.com/resources/knowledge-base/exporting-data/data-dictionary on October 14th 2019), the **"standard"** sleep classification system consists of a first processing step (called "**Level**") where each epoch is scored as "*wake*" (**10**), "*light*" (**2**), "*deep*" (**3**), and "*rem*" (**5**). Then, a second processing step called "**ShortWakes**" (SW) applies a further processing to detect awakenings/arousals lasting "less than 180 seconds". In the SW system, the information on the Level is combined with the ShortWakes information to adjust wake missdetection (e.g., epochs scored as light sleep by the "standard" system but corresponding to a short wakes will be recoded as "wake").

If this is the case, the number of discrepancies between the "standard" and the SW system should be very small (since short awakeings/arousals are supposed to be relatively unfrequent), and all discrepancies should have negative values (i.e., **-8** when "light" is recoded as "wake", **-7** when "deep" is recoded as "wake", and **-5** when "REM" is recoded as "wake"). No positive values (i.e., cases where wake is recoded as sleep) should be shown.

<br>

```{r warning=FALSE,message=FALSE}

# differences between "classic" and "new" classification
ebe$diff <- ebe$Classic_FB - ebe$New_FB

# total number of epochs
N <- nrow(ebe)

# number of epochs with a discrepancy between "classic" and "new"
nrow(ebe[ebe$diff!=0,])

# percentage of epochs with a discrepancy between "classic" and "new"
round(100*nrow(ebe[ebe$diff!=0,])/N,2)

# number of discrepancies > 0
nrow(ebe[ebe$diff>0,])

# summary of discrepancies
summary(as.factor(ebe$diff))

# percentage of discrepancies
summary(as.factor(ebe$diff))/nrow(ebe[ebe$diff!=0,])*100

# removing the "diff" column
ebe$diff <- NULL

```

<br>

*Comments:*

- Discrepancies between the "standard" and the SW classification system are shown **only by the 3.24% of the epochs**, confirming that the difference regards only very few cases.

- Differences are **all negative**, confirming that the "new" system is just a "correction" of wake epochs missdetected by the "classic" classification.

- Most differences are scored as **-8**, indicating "light" epochs recoded as "wake", whereas a minority of discrepancies have value -7 ("deep" to "wake") and -5 ("REM" to "wake").

<br>

*Conclusions:*

It is confirmed that the "new" classification system applies a "correction" of the sleep Level (i.e., stage) classified by the "classic" system, by taking into account the cases of short awakenings/arousals. This correction should result in less cases of false negative (i.e., wake scored as sleep) and thus, higher specificity. However, the differences are shown only by the 3.24% of the epochs. Consequently, the improvement in measurement specificity is expected to be almost irrelevant.

<br>

### SLEEP METRICS FILES

<br>

Here, we load the files including the sleep metrics (total sleep time, sleep efficiency, etc.) computed through FC2 and PSG. The data are stored in two files: the former includes measures derived from the "standard" FC2 classification, and the latter includes the SW-adjusted measures (see previous section).

<br>

```{r warning=FALSE,message=FALSE}

sleep.classic <- read_excel("AA_PSG_fb_comp_group_classic.xlsx")
sleep.new <- read_excel("AA_PSG_fb_comp_group_newStages.xlsx")

```

<br>

### DATA DICTIONARY

<br>

In the previous sections, two datasets have been created: ...

<br>

# 2. Bland-Altman analyses   {.tabset .tabset-fade .tabset-pills}

<br>

In this section, the **sleep metrics files** are used to conduct a **Bland-Altman (BA) analysis**. BA analysis allows to evaluate the agreement between a method under assessment (i.e., FC2) and a gold-standard method (i.e., PSG) by plotting the differences between measures derived with the two measurement systems against their averages (Bland & Altman, 1990). An alternative approach is to plot differences over gold-standard-derived measures (...). In both cases, the agreement is expressed in terms of bias (i.e., mean difference) and 95% limits of agreement (LOAs, i.e., bias ± 1.96 SD), both expressed in the original measurement units.

<br>

```{r warning=FALSE,message=FALSE}

# required packages
library(BlandAltmanLeh); library(ggplot2); library(ggExtra); library(mgsub); library(gridExtra)
windowsFonts(CMU=windowsFont("CMU Serif Roman"),Times=windowsFont("Times New Roman"))

```

<br>

### Pipeline

<br>

Here, we show an example with Total Sleep Time (TST).

First, we store the BA statistics computed through the BlandAltmanLeh package into an object called ba.stat. Note that here we are considering **PSG - FC2** differences. Thus, positive biases represent cases of underestimation (i.e., FC2 is lower than PSG), and negative biases represent cases of overestimation (i.e., FC2 is higher than PSG).

<br>

```{r warning=FALSE,message=FALSE}

ba.stat <- bland.altman.stats(sleep.classic$TST_PSG,sleep.classic$TST_Fb,conf.int=.95)

# PSG and FC2 scores, means and differences night-by-night
cbind(ba.stat$groups,ba.stat$means,ba.stat$diffs)

# bias
ba.stat$mean.diffs

# lower and upper LOA
ba.stat$lower.limit 
ba.stat$upper.limit

# confidence intervals
ba.stat$CI.lines

```

<br>

Then, we test the two assumptions of BA analyses:

1. the reference values (here, PSG-derived values) and the differences should be **uncorrelated**.

<br>

```{r warning=FALSE,message=FALSE}

# correlation significance test between reference values and differences
correlation <- cor.test(ba.stat$groups$group1,ba.stat$diffs)
correlation$p.value >= .05 # TRUE if uncorrelated

```

<br>

2. the differences should be **normally distributed**.

<br>

```{r warning=FALSE,message=FALSE}

# differences Shapiro-Wilk test of normality
shapiro <- shapiro.test(ba.stat$diffs)
shapiro$p.value >= .05 # TRUE if normally distributed

```

<br>

In this case, the data meet the correlation criterion but not the differences normality. Thus, we can consider the values in the original measurement units but caution should be posed when interpeting the 95% LOAs and CI.

The final step is storing the computed indices and generating the BA plot.

<br>

```{r warning=FALSE,message=FALSE}

# over- or underestimation
if(ba.stat$CI.lines[3]>0){
    estimation = "UNDER"
  } else if(ba.stat$CI.lines[4]<0) {
    estimation = "OVER"
  } else {
    estimation = "-"
  }

# storing BA statistics
data.frame(measure="TST",
           bias=paste(round(ba.stat$mean.diffs,2)," (",
                      as.numeric(round(ba.stat$CI.lines[3],2)),", ",
                      as.numeric(round(ba.stat$CI.lines[4],2)),")",sep=""),
           LOAs=paste(round(ba.stat$lower.limit,2)," (",
                      as.numeric(round(ba.stat$CI.lines[1],2)),", ",
                      as.numeric(round(ba.stat$CI.lines[2],2)),"), ",
                      round(ba.stat$upper.limit,2)," (",
                      as.numeric(round(ba.stat$CI.lines[5],2)),", ",
                      as.numeric(round(ba.stat$CI.lines[6],2)),")",sep=""),
           estimation=estimation)

# Bland-altman plot
ba <- data.frame(PSG=ba.stat$groups$group1,diffs=ba.stat$diffs)
p <- ggplot(data=ba,aes(PSG,diffs)) + 
  
  # BIAS
  geom_line(aes(y=ba.stat$mean.diffs),colour="red",linetype=2,size=1.5) +
  geom_line(aes(y=ba.stat$CI.lines[3]),colour="red",linetype=2,size=1) +
  geom_line(aes(y=ba.stat$CI.lines[4]),colour="red",linetype=2,size=1) +
    
  # UPPER LIMIT
  geom_line(aes(y=ba.stat$upper.limit),colour="darkgray",linetype=2,size=1.3) +
  geom_line(aes(y=ba.stat$CI.lines[5]),colour="darkgray",linetype=2,size=1) +
  geom_line(aes(y=ba.stat$CI.lines[6]),colour="darkgray",linetype=2,size=1) +
    
  # LOWER LIMIT
  geom_line(aes(y=ba.stat$lower.limit),colour="darkgray",linetype=2,size=1.3) +
  geom_line(aes(y=ba.stat$CI.lines[1]),colour="darkgray",linetype=2,size=1) +
  geom_line(aes(y=ba.stat$CI.lines[2]),colour="darkgray",linetype=2,size=1) +
  
  geom_point(size=2.5) +
    
  xlab("PSG-derived total sleep time (min)") + 
  ylab("PSG - FC2 differences in \ntotal sleep time (min)") +
    
  theme(axis.text = element_text(size=12,family="Times",face="bold"),
        axis.title = element_text(size=16,colour="black",family="Times",face="bold"),
        plot.title = element_text(hjust = 0.5,size=16,family="Times",face="bold"))
  # p
  # plotting criterion only if included
  # if(max(ba.stat$CI.lines[6]) > CRITERION){
  #   p <- p + geom_line(aes(y=CRITERION),
  #                      colour="blue",size=1.5)
  # }                 
  print(ggMarginal(p,fill="lightgray",colour="lightgray",
                   # type="violin",colour="#A90302",
                   size=4,margins="y"))

```

<br>

A different procedure should be used **when a correlation is observed** between reference values and differences. According to Euser, Dekker, & le Cessie (2008), when a significant correlation is found between differences and PSG-derived scores, data should be log-transformed and results should be reported as **bias ± 2 × PSG-derived measure (e^a – 1) / (e^a + 1)**, where a is 1.96 standard deviations of the differences in the log scale.

<br>

```{r warning=FALSE,message=FALSE}

# 1. Logarithmic transformation of data
ba.stat$groups$LOGgroup1 <- log(ba.stat$groups$group1) 
ba.stat$groups$LOGgroup2 <- log(ba.stat$groups$group2)
ba.stat$groups$LOGdiff <- ba.stat$groups$LOGgroup1 - ba.stat$groups$LOGgroup2
    
# 2. Bland-Altman statistics on logaritmic data
ba.stat$lines.LOG <- c(lower.limit = -1.96*sd(ba.stat$groups$LOGdiff),
                       mean.diffs = mean(ba.stat$groups$LOGdiff),
                       upper.limit = 1.96*sd(ba.stat$groups$LOGdiff))
t1 <- qt((1 - 0.95)/2, df = ba.stat$based.on - 1) # t-value right
t2 <- qt((0.95 + 1)/2, df = ba.stat$based.on - 1) # t-value left

# confidence intervals
ba.stat$CI.lines.LOG <- c(lower.limit.ci.lower = ba.stat$lines.LOG[1] +
                            t1 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on),
                          lower.limit.ci.upper = ba.stat$lines.LOG[1] + 
                            t2 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on), 
                          mean.diff.ci.lower = ba.stat$lines.LOG[2] +
                            t1 * sd(ba.stat$groups$LOGdiff)/sqrt(ba.stat$based.on), 
                          mean.diff.ci.upper = ba.stat$lines.LOG[2] + 
                            t2 * sd(ba.stat$groups$LOGdiff)/sqrt(ba.stat$based.on), 
                          upper.limit.ci.lower = ba.stat$lines.LOG[3] +
                            t1 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on), 
                          upper.limit.ci.upper = ba.stat$lines.LOG[3] +
                            t2 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on))
    
# 3. Antilog transformation (geometric mean ratio)
# "the ratio between the two measurements (X1/X2) is between 10^-a and 10^a", where a is -1.96 SD in the log scale"
ba.stat$lines.ANTILOG <- exp(ba.stat$lines.LOG)
ba.stat$CI.lines.ANTILOG <- exp(ba.stat$CI.lines.LOG)
ba.stat$groups$ratio <- ba.stat$groups$group1/ba.stat$groups$group2
ba.stat$groups$GEOMETRICmeans <- sqrt(ba.stat$groups$group1*ba.stat$groups$group2)
    
# 4. Antilog transformation: differences depending on mean (based on Euser et al 2008)
# LOAs are computed as -2meanBIAS*(e^a-1)/(10^a+1) and +2BIAS*(e^a-1)/(10^a+1)
ba.stat$LOA.slope <- 2 * (exp(1.96 * sd(ba.stat$groups$LOGdiff)) - 1) /
  (exp(1.96*sd(ba.stat$groups$LOGdiff)) + 1)
# LOAs 95% CI limits are computed as -2meanBIAS*e^(a+CI)-1)/(10^(a+CI)+1) and +2meanBIAS*e^(a+CI)-1)/(10^(a+CI)+1)
ba.stat$CI.slope.lower <- 2 * (exp(1.96 * sd(ba.stat$groups$LOGdiff) +
                                     t1 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on)) - 1) /
  (exp(1.96*sd(ba.stat$groups$LOGdiff) + t1 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on)) + 1)
ba.stat$CI.slope.upper <- 2 * (exp(1.96 * sd(ba.stat$groups$LOGdiff) +
                                     t2 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on)) - 1) /
  (exp(1.96*sd(ba.stat$groups$LOGdiff) + t2 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on)) + 1)
    
# Recomputing confidence intervals
ba.stat$groups$ANTLOGdiffs.upper <- ba.stat$means * ba.stat$LOA.slope
ba.stat$groups$ANTLOGdiffs.upper.lower <- ba.stat$means*ba.stat$CI.slope.lower
ba.stat$groups$ANTLOGdiffs.upper.upper <- ba.stat$means*ba.stat$CI.slope.upper
ba.stat$groups$ANTLOGdiffs.lower <- ba.stat$means*(-1)*ba.stat$LOA.slope
ba.stat$groups$ANTLOGdiffs.lower.lower <- ba.stat$means*(-1)*ba.stat$CI.slope.upper
ba.stat$groups$ANTLOGdiffs.lower.upper <- ba.stat$means*(-1)*ba.stat$CI.slope.lower
  

```

<br>

Again, the final step is storing the computed indices and generating the BA plot.

<br>

```{r warning=FALSE,message=FALSE}

# over- or underestimation
if(ba.stat$CI.lines[3]>0){
    estimation = "OVER"
  } else if(ba.stat$CI.lines[4]<0) {
    estimation = "UNDER"
  } else {
    estimation = "-"
  }

# storing BA statistics
data.frame(measure="TST",
           bias=paste(round(ba.stat$mean.diffs,2)," (",
                      as.numeric(round(ba.stat$CI.lines[3],2)),", ",
                      as.numeric(round(ba.stat$CI.lines[4],2)),")",sep=""),
           LOAs=paste(round(ba.stat$mean.diffs,2)," ± PSG x ",round(ba.stat$LOA.slope,2),
                      " (",round(ba.stat$CI.slope.lower,2),", ",round(ba.stat$CI.slope.upper,2),") ",
                      sep=""),
           estimation=estimation)

# Bland-altman plot
ba <- data.frame(PSG=ba.stat$groups$group1,diffs=ba.stat$diffs)
p <- ggplot(data=ba,aes(PSG,diffs)) +
  
  # BIAS
  geom_line(aes(y=ba.stat$mean.diffs),colour="red",linetype=2,size=1.5) +
  geom_line(aes(y=ba.stat$CI.lines[3]),colour="red",linetype=2,size=1) +
  geom_line(aes(y=ba.stat$CI.lines[4]),colour="red",linetype=2,size=1) +
  
  # LOWER LIMIT
  geom_line(aes(ba.stat$means,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.lower),
            colour="darkgray",linetype=2,size=1.3) +
  geom_line(aes(ba.stat$means,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.lower.upper),
            colour="darkgray",linetype=2,size=1) +
  geom_line(aes(ba.stat$means,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.lower.lower),
            colour="darkgray",linetype=2,size=1) +
  
  # UPPER LIMIT
  geom_line(aes(ba.stat$means,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.upper),
            colour="darkgray",linetype=2,size=1.3) +
  geom_line(aes(ba.stat$means,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.upper.upper),
            colour="darkgray",linetype=2,size=1) +
  geom_line(aes(ba.stat$means,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.upper.lower),
            colour="darkgray",linetype=2,size=1) +
  
  geom_point(size=2.5) +
  
  xlab("PSG-derived total sleep time (min)") + 
  ylab("PSG - FC2 differences in \ntotal sleep time (min)") +
  
  theme(axis.text = element_text(size=12,family="Times",face="bold"),
            axis.title = element_text(size=16,colour="black",
                                      family="Times",face="bold"),
            plot.title = element_text(hjust = 0.5,size=16,
                                      family="Times",face="bold"))
    
    # plotting criterion only if included
  # if(max(ba.stat$CI.lines[6]) > CRITERION){
  #   p <- p + geom_line(aes(y=CRITERION),
  #                      colour="blue",size=1.5)
  # }                 
  print(ggMarginal(p,fill="lightgray",colour="lightgray",
                   # type="violin",colour="#A90302",
                   size=4,margins="y"))

```

<br>

### Function

<br>

Now we can create a function to automatize the procedure reported in the previous section.

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis <- function(group1,group2,measure="TST",doPlot=TRUE,ylim=NA,message=TRUE,return.data="data",title=NA){
  
  # computing BA statistics
  ba.stat <- bland.altman.stats(group1,group2,conf.int=.95)
  
  # over or underestimation
  if(ba.stat$CI.lines[3]>0){ estimation = "UNDER" 
  } else if(ba.stat$CI.lines[4]<0) { estimation = "OVER"
  } else { estimation = "-" }
  
  # BA assumptions
  correlation <- cor.test(ba.stat$groups$group1,ba.stat$diffs) # correlation reference-differences
  shapiro <- shapiro.test(ba.stat$diffs) # shapiro-wilk test of normality
  
  # when reference and differences are *not* correlated
  if(correlation$p.value>=.05){
    
    # BA statistics
    out <- data.frame(measure=measure,
                      bias=paste(round(ba.stat$mean.diffs,2)," (",
                                 as.numeric(round(ba.stat$CI.lines[3],2)),", ",
                                 as.numeric(round(ba.stat$CI.lines[4],2)),")",sep=""),
                      LOA.upper=paste(round(ba.stat$upper.limit,2)," (",
                                      as.numeric(round(ba.stat$CI.lines[5],2)),", ",
                                      as.numeric(round(ba.stat$CI.lines[6],2)),")",sep=""),
                      LOA.lower=paste(round(ba.stat$lower.limit,2)," (",
                                      as.numeric(round(ba.stat$CI.lines[1],2)),", ",
                                      as.numeric(round(ba.stat$CI.lines[2],2)),")",sep=""),
                      estimation=estimation)
    
    # BA plot
    ba <- data.frame(PSG=ba.stat$groups$group1,diffs=ba.stat$diffs)
    p <- ggplot(data=ba,aes(PSG,diffs)) + 
      
      # BIAS
      geom_line(aes(y=ba.stat$mean.diffs),colour="red",linetype=2,size=1.5) +
      geom_line(aes(y=ba.stat$CI.lines[3]),colour="red",linetype=2,size=1) +
      geom_line(aes(y=ba.stat$CI.lines[4]),colour="red",linetype=2,size=1) +
      
      # UPPER LIMIT
      geom_line(aes(y=ba.stat$upper.limit),colour="darkgray",linetype=2,size=1.3) +
      geom_line(aes(y=ba.stat$CI.lines[5]),colour="darkgray",linetype=2,size=1) +
      geom_line(aes(y=ba.stat$CI.lines[6]),colour="darkgray",linetype=2,size=1) +
      
      # LOWER LIMIT
      geom_line(aes(y=ba.stat$lower.limit),colour="darkgray",linetype=2,size=1.3) +
      geom_line(aes(y=ba.stat$CI.lines[1]),colour="darkgray",linetype=2,size=1) +
      geom_line(aes(y=ba.stat$CI.lines[2]),colour="darkgray",linetype=2,size=1)
    
    
  } else { # when reference and differences are correlated (LOG-TRANSFORMATION)
      
    # 1. Logarithmic transformation of data (adding little constant to avoid Inf values)
    ba.stat$groups$LOGgroup1 <- log(ba.stat$groups$group1 + .0001)
    ba.stat$groups$LOGgroup2 <- log(ba.stat$groups$group2 + .0001)
    ba.stat$groups$LOGdiff <- ba.stat$groups$LOGgroup1 - ba.stat$groups$LOGgroup2
    
    # 2. Bland-Altman statistics on logaritmic data
    ba.stat$lines.LOG <- c(lower.limit = -1.96*sd(ba.stat$groups$LOGdiff),
                           mean.diffs = mean(ba.stat$groups$LOGdiff),
                           upper.limit = 1.96*sd(ba.stat$groups$LOGdiff))
    t1 <- qt((1 - 0.95)/2, df = ba.stat$based.on - 1) # t-value right
    t2 <- qt((0.95 + 1)/2, df = ba.stat$based.on - 1) # t-value left
    
    # confidence intervals
    ba.stat$CI.lines.LOG <- c(lower.limit.ci.lower = ba.stat$lines.LOG[1] +
                                t1 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on),
                              lower.limit.ci.upper = ba.stat$lines.LOG[1] + 
                                t2 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on), 
                              mean.diff.ci.lower = ba.stat$lines.LOG[2] +
                                t1 * sd(ba.stat$groups$LOGdiff)/sqrt(ba.stat$based.on), 
                              mean.diff.ci.upper = ba.stat$lines.LOG[2] + 
                                t2 * sd(ba.stat$groups$LOGdiff)/sqrt(ba.stat$based.on), 
                              upper.limit.ci.lower = ba.stat$lines.LOG[3] +
                                t1 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on), 
                              upper.limit.ci.upper = ba.stat$lines.LOG[3] +
                                t2 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 3/ba.stat$based.on))
    
    # 4. Antilog transformation: differences depending on mean (based on Euser et al 2008)
    ba.stat$LOA.slope <- 2 * (exp(1.96 * sd(ba.stat$groups$LOGdiff)) - 1) /
      (exp(1.96*sd(ba.stat$groups$LOGdiff)) + 1)
    ba.stat$CI.slope.lower <- 2 * (exp(1.96 * sd(ba.stat$groups$LOGdiff) +
                                     t1 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 
                                                 3/ba.stat$based.on)) - 1) /
      (exp(1.96*sd(ba.stat$groups$LOGdiff) + t1 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 
                                                         3/ba.stat$based.on)) + 1)
    ba.stat$CI.slope.upper <- 2 * (exp(1.96 * sd(ba.stat$groups$LOGdiff) +
                                         t2 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 
                                                     3/ba.stat$based.on)) - 1) /
      (exp(1.96*sd(ba.stat$groups$LOGdiff) + t2 * sqrt(sd(ba.stat$groups$LOGdiff)^2 * 
                                                         3/ba.stat$based.on)) + 1)
    
    # Recomputing confidence intervals as slopes
    ba.stat$groups$ANTLOGdiffs.upper <- ba.stat$groups$group1 * ba.stat$LOA.slope
    ba.stat$groups$ANTLOGdiffs.upper.lower <- ba.stat$groups$group1 * ba.stat$CI.slope.lower
    ba.stat$groups$ANTLOGdiffs.upper.upper <- ba.stat$groups$group1 * ba.stat$CI.slope.upper
    ba.stat$groups$ANTLOGdiffs.lower <- ba.stat$groups$group1 * (-1)*ba.stat$LOA.slope
    ba.stat$groups$ANTLOGdiffs.lower.lower <- ba.stat$groups$group1 * (-1)*ba.stat$CI.slope.upper
    ba.stat$groups$ANTLOGdiffs.lower.upper <- ba.stat$groups$group1 * (-1)*ba.stat$CI.slope.lower
    
    # BA statistics
    out <- data.frame(measure=measure,
                      bias=paste(round(ba.stat$mean.diffs,2)," (",
                                 as.numeric(round(ba.stat$CI.lines[3],2)),", ",
                                 as.numeric(round(ba.stat$CI.lines[4],2)),")",sep=""),
                      LOA.upper=paste(round(ba.stat$mean.diffs,2)," + PSG x ",round(ba.stat$LOA.slope,2),
                                      " (",round(ba.stat$CI.slope.lower,2),", ",
                                      round(ba.stat$CI.slope.upper,2),") ",
                                      sep=""),
                      LOA.lower=paste(round(ba.stat$mean.diffs,2)," - PSG x ",round(ba.stat$LOA.slope,2),
                                      " (",round(ba.stat$CI.slope.lower,2),", ",
                                      round(ba.stat$CI.slope.upper,2),") ",
                                      sep=""),
                      estimation=estimation)

    # BA plot
    ba <- data.frame(PSG=ba.stat$groups$group1,diffs=ba.stat$diffs)
    p <- ggplot(data=ba,aes(PSG,diffs)) +
  
      # BIAS
      geom_line(aes(y=ba.stat$mean.diffs),colour="red",linetype=2,size=1.5) +
      geom_line(aes(y=ba.stat$CI.lines[3]),colour="red",linetype=2,size=1) +
      geom_line(aes(y=ba.stat$CI.lines[4]),colour="red",linetype=2,size=1) +
  
      # LOWER LIMIT
      geom_line(aes(ba.stat$groups$group1,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.lower),
                colour="darkgray",linetype=2,size=1.3) +
      geom_line(aes(ba.stat$groups$group1,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.lower.upper),
                colour="darkgray",linetype=2,size=1) +
      geom_line(aes(ba.stat$groups$group1,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.lower.lower),
                colour="darkgray",linetype=2,size=1) +
  
      # UPPER LIMIT
      geom_line(aes(ba.stat$groups$group1,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.upper),
                colour="darkgray",linetype=2,size=1.3) +
      geom_line(aes(ba.stat$groups$group1,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.upper.upper),
                colour="darkgray",linetype=2,size=1) +
      geom_line(aes(ba.stat$groups$group1,ba.stat$mean.diffs + ba.stat$groups$ANTLOGdiffs.upper.lower),
                colour="darkgray",linetype=2,size=1)
  }
  
  # changing plot labels
  measure <- mgsub(string=measure,
                   pattern=c("TST","SE","SOL","WASO","Light","Deep","REM"),
                   replacement=c("total sleep time (min)","sleep efficiency (%)",
                                 "sleep onset latency (min)","wake after sleep onset (min)",
                                 "'light' sleep duration (min)","'deep' sleep duration (min)",
                                 "REM sleep duration (min)"))
  
  # adding graphical elements and axis labels to BA plot
  p <- p + geom_point(size=2.5) +
    xlab(paste("PSG-derived",measure)) + 
    ylab(paste("PSG - FC2 differences in\n",measure,sep="")) +
    theme(axis.text = element_text(size=12,family="Times",face="bold"),
          axis.title = element_text(size=12,colour="black",family="Times",face="bold"),
          plot.title = element_text(hjust = 0.5,size=12,family="Times",face="bold"))
  if(!is.na(ylim)){
      p <- p + ylim(ylim) 
  }
  if(!is.na(title)){
    p <- p + ggtitle(title)
  }
  
  if(doPlot==TRUE){
    print(ggMarginal(p,fill="lightgray",colour="lightgray",size=4,margins="y"))
  }
  
  if(message==TRUE){
    ifelse(correlation$p.value>0.05,
           print("uncorrelated"),
           print(paste("CORRELATED! Pearson's coeff =",as.numeric(round(correlation$estimate,2)))))
    ifelse(shapiro$p.value>0.05,
           print("normally distributed"),
           print(paste("NOT NORMAL! Caution should be posed! Shapiro-Wilk statistic =",
                       as.numeric(round(shapiro$statistic,2)),"p =",as.numeric(round(shapiro$p.value,2)))))
  }
  
  if(return.data=="data"){
    return(out)
  } else if(return.data=="plot"){
    return(ggMarginal(p,fill="lightgray",colour="lightgray",size=4,margins="y"))
  }
  
}


```

<br>

Let's try our function with TST.

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.classic$TST_PSG,sleep.classic$TST_Fb,measure="TST")

```

<br>

Let's try our function with WASO.

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.classic$WASO_PSG,sleep.classic$WASO_Fb,measure="WASO",ylim=c(-25,75))

```

<br>

Let's try with REM sleep.

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.classic$REM_PSG,sleep.classic$REM_Fb,measure="REM",ylim=c(-100,100))

```

<br>

### Results (standard FC2) {.tabset .tabset-fade .tabset-pills}

<br>

Here, we can use our function (see the previous sections) to generate the results of the BA analysis.

<br>

#### BA Table

<br>

First, we can generate a table summarizing all the results.

<br>

```{r warning=FALSE,message=FALSE}

library(knitr)

ba_results <- rbind(ba_analysis(sleep.classic$TST_PSG,sleep.classic$TST_Fb,measure="TST",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.classic$SE_PSG,sleep.classic$SE_Fb,measure="SE",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.classic$SOL_PSG,sleep.classic$SOL_Fb,measure="SOL",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.classic$WASO_PSG,sleep.classic$WASO_Fb,measure="WASO",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.classic$Light_PSG,sleep.classic$Light_Fb,measure="Light",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.classic$Deep_PSG,sleep.classic$Deep_Fb,measure="Deep",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.classic$REM_PSG,sleep.classic$REM_Fb,measure="REM",
                                doPlot=FALSE,message=FALSE))

kable(ba_results)

```

<br>

#### TST

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.classic$TST_PSG,sleep.classic$TST_Fb,measure="TST",ylim=c(-80,50))

```

<br>

*Comments:*

- 

- 

<br>

#### SE

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.classic$SE_PSG,sleep.classic$SE_Fb,measure="SE",ylim=c(-20,15))

```

<br>

*Comments:*

- 

- 

<br>

#### SOL

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.classic$SOL_PSG,sleep.classic$SOL_Fb,measure="SOL",ylim=c(-40,40))

```

<br>

*Comments:*

- 

- 

<br>

#### WASO

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.classic$WASO_PSG,sleep.classic$WASO_Fb,measure="WASO",ylim=c(-30,60))

```

<br>

*Comments:*

- 

- 

<br>

#### light

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.classic$Light_PSG,sleep.classic$Light_Fb,measure="Light",ylim=c(0,45))

```

<br>

*Comments:*

- 

- 

<br>

#### deep

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.classic$Deep_PSG,sleep.classic$Deep_Fb,measure="Deep",ylim=c(-100,100))

```

<br>

*Comments:*

- 

- 

<br>

#### REM

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.classic$REM_PSG,sleep.classic$REM_Fb,measure="REM",ylim=c(-75,75))

```

<br>

*Comments:*

- 

- 

<br>

*Conclusions:*

Overall,

<br>

### Results (SW update) {.tabset .tabset-fade .tabset-pills}

<br>

Here, we can replicate the BA analysis on the sleep metrics obtained using the **FC2 SW-update**.

<br>

#### BA Table

<br>

First, we can generate a table summarizing all the results.

<br>

```{r warning=FALSE,message=FALSE}

ba_results <- rbind(ba_analysis(sleep.new$TST_PSG,sleep.new$TST_Fb,measure="TST",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.new$SE_PSG,sleep.new$SE_Fb,measure="SE",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.new$SOL_PSG,sleep.new$SOL_Fb,measure="SOL",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.new$WASO_PSG,sleep.new$WASO_Fb,measure="WASO",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.new$Light_PSG,sleep.new$Light_Fb,measure="Light",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.new$Deep_PSG,sleep.new$Deep_Fb,measure="Deep",
                                doPlot=FALSE,message=FALSE),
                    ba_analysis(sleep.new$REM_PSG,sleep.new$REM_Fb,measure="REM",
                                doPlot=FALSE,message=FALSE))

kable(ba_results)

```

<br>

#### TST

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.new$TST_PSG,sleep.new$TST_Fb,measure="TST",ylim=c(-80,50))

```

<br>

*Comments:*

- 

- 

<br>

#### SE

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.new$SE_PSG,sleep.new$SE_Fb,measure="SE",ylim=c(-20,15))

```

<br>

*Comments:*

- 

- 

<br>

#### SOL

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.new$SOL_PSG,sleep.new$SOL_Fb,measure="SOL",ylim=c(-40,40))

```

<br>

*Comments:*

- 

- 

<br>

#### WASO

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.new$WASO_PSG,sleep.new$WASO_Fb,measure="WASO",ylim=c(-30,60))

```

<br>

*Comments:*

- 

- 

<br>

#### light

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.new$Light_PSG,sleep.new$Light_Fb,measure="Light",ylim=c(0,45))

```

<br>

*Comments:*

- 

- 

<br>

#### deep

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.new$Deep_PSG,sleep.new$Deep_Fb,measure="Deep",ylim=c(-100,100))

```

<br>

*Comments:*

- 

- 

<br>

#### REM

<br>

```{r warning=FALSE,message=FALSE}

ba_analysis(sleep.new$REM_PSG,sleep.new$REM_Fb,measure="REM",ylim=c(-75,75))

```

<br>

*Comments:*

- 

- 

<br>

*Conclusions:*

Overall,

<br>

# 3. Epoch-by-epoch analysis  {.tabset .tabset-fade .tabset-pills}

<br>

In this section, the **epoch-by-epoch (EBE)** raw data are recoded to a binary format for each sleep stage (e.g., 0 = REM, 1 = non-REM). Then, the recoded data are used to compute the confusion matrix, based on which EBE statistics (i.e., sensitivity, specificity, accuracy, PPV, NPV, and Cohen's kappa) are calculated. The same procedure is applied to both the "standard" and the SW-adjusted FC2 classification.

<br>

```{r warning=FALSE,message=FALSE}

library(ROCR); library(caret); library(epiR); library(knitr) # required packages

```

<br>

### Pipeline

<br>

Here we show an example with "wake" vs. "non-wake" epochs.

Since we have more than two conditions (i.e., "wake", "light", "sleep" and "REM"), a first step consists in **dychotomizing the scores** for each stage (i.e., 1 = that sage, 0 = all other stages). 

<br>

```{r warning=FALSE,message=FALSE}

# Fitbit dychotomous recoding
ebe$wake.FB = NA
ebe[ebe$Classic_FB==10,"wake.FB"] = 1 # wake = 1
ebe[ebe$Classic_FB!=10,"wake.FB"] = 0 # non-wake (sleep) = 0

# PSG dychotomous recoding
ebe$wake.PSG <- NA
ebe[ebe$PSG==10,"wake.PSG"] = 1 # wake = 1
ebe[ebe$PSG!=10,"wake.PSG"] = 0 # non-wake (sleep) = 0

# FC2 sanity check (everything should be 0 or 1)
levels(as.factor(ebe$wake.FB))

# PSG sanity check (everything should be 0 or 1)
levels(as.factor(ebe$wake.PSG))

ebe[,c("Classic_FB","wake.FB","PSG","wake.PSG")]

```

<br>

As a second step, we generate an **absolute confusion matrix** (contingent matrix), which stores the informations on positive (i.e., wake) and negative epochs (i.e., non-wake) scored by PSG and Fitbit.

<br>

```{r warning=FALSE,message=FALSE}

# confusion matrix labels
data.frame(Fitbit=c("wake","sleep"),
           PSG_wake=c("true wake","false sleep"),
           PSG_sleep=c("false wake","true sleep"))

# confusion matrix wake (positive) vs. non-wake (negative)
confMatrix <- data.frame(Fitbit=c("wake","sleep"),
                         PSG_wake=c(nrow(ebe[ebe$wake.FB==1 & ebe$wake.PSG==1,]), # true wake
                                    nrow(ebe[ebe$wake.FB==0 & ebe$wake.PSG==1,])), # false sleep
                         PSG_sleep=c(nrow(ebe[ebe$wake.FB==1 & ebe$wake.PSG==0,]), # false wake
                                     nrow(ebe[ebe$wake.FB==0 & ebe$wake.PSG==0,]))) # true sleep
confMatrix

```

<br>

Then, the confusion matrix can be used to compute the **EBE statistics**: Accuracy, Sensitivity, Specificity, Positive predictive value (PPV) and Negative predictive value (NPV).

<br>

```{r warning=FALSE,message=FALSE}

# accuracy = (true positives + true negatives) / total number of cases
(acc <- round((confMatrix[1,2]+confMatrix[2,3])/
                (confMatrix[1,2]+confMatrix[2,2]+confMatrix[1,3]+confMatrix[2,3]),2))

# sensitivity = true positives / (true positives + false negatives)
(sens <- round(confMatrix[1,2]/(confMatrix[1,2]+confMatrix[2,2]),2))

# specificity = true negatives / (true negatives + false positives)
(spec <- round(confMatrix[2,3]/(confMatrix[2,3]+confMatrix[1,3]),2))

# prevalence = (true positives + false negatives) / total number of cases
(prev <- round((confMatrix[1,2]+confMatrix[2,2])/
                 (confMatrix[1,2]+confMatrix[2,2]+confMatrix[1,3]+confMatrix[2,3]),2))

# PPV = (sensitivity * prevalence) / ((sensitivity * prevalence) + (1 - specificity) * (1 - prevalence))
(ppv <- round((sens*prev)/(sens*prev + (1-spec)*(1-prev)),2))

# NPV = (specificity * (1-prevalence) / ((1-sensitivity) * prevalence + specificity * (1-prevalence))
(npv <- round((spec*(1-prev))/((1-sens)*prev + spec*(1-prev)),2))

```

<br>

A **sanity check** of our procedure can be performed by comparing the results with those obtained with two published packages: ROCR and caret.

<br>

```{r warning=FALSE,message=FALSE}

# accuracy (ROCR)
round(performance(prediction(ebe$wake.FB,ebe$wake.PSG),"acc")@y.values[[1]][2],2) == acc

# sensitivity (ROCR)
round(performance(prediction(ebe$wake.FB,ebe$wake.PSG),"sens")@y.values[[1]][2],2) == sens

# sensitivity (caret)
round(sensitivity(factor(ebe$wake.FB,levels=c(1,0),labels=c("sleep","wake")),
                  factor(ebe$wake.PSG,levels=c(1,0),labels=c("sleep","wake"))),2) == sens

# specificity (ROCR)
round(performance(prediction(ebe$wake.FB,ebe$wake.PSG),"spec")@y.values[[1]][2],2) == sens

# specificity (caret)
round(specificity(factor(ebe$wake.FB,levels=c(1,0),labels=c("sleep","wake")),
                  factor(ebe$wake.PSG,levels=c(1,0),labels=c("sleep","wake"))),2) == spec

# PPV (ROCR)
round(performance(prediction(ebe$wake.FB,ebe$wake.PSG),"ppv")@y.values[[1]][2],2) == ppv

# PPV (caret)
round(posPredValue(factor(ebe$wake.FB,levels=c(1,0),labels=c("sleep","wake")),
                   factor(ebe$wake.PSG,levels=c(1,0),labels=c("sleep","wake"))),2) == ppv

# NPV (ROCR)
round(performance(prediction(ebe$wake.FB,ebe$wake.PSG),"npv")@y.values[[1]][2],2) == npv

# NPV (caret)
round(negPredValue(factor(ebe$wake.FB,levels=c(1,0),labels=c("sleep","wake")),
                   factor(ebe$wake.PSG,levels=c(1,0),labels=c("sleep","wake"))),2) == npv

```

<br>

*Comments:*

- our results are equivalent to those obtained using the ROCR and the caret packages.

The accuracy of both the "new" and the "classic" Fitbit classification systems can be compared also by plotting the Receiver Operating Characteristic (**ROC**) curves, using the ROCR package. Here, the graph suggests that the SW-adjusted classification (in red) is sligthly more accurate in detecting wake compared to the "standard" FC2 system.

<br>

```{r warning=FALSE,message=FALSE}

# Fitbit "new" dychotomous recoding
ebe$wake.FB_new = NA
ebe[ebe$New_FB==10,"wake.FB_new"] = 1 # wake = 1
ebe[ebe$New_FB!=10,"wake.FB_new"] = 0 # non-wake (sleep) = 0

# ROC curves
plot(performance(prediction(ebe$wake.FB,ebe$wake.PSG),"tpr","fpr"), 
     main="Fitbit wake detection",xlab="1-specificity",ylab="sensitivity",
     lwd=2)
par(new=TRUE)
plot(performance(prediction(ebe$wake.FB_new,ebe$wake.PSG),"tpr","fpr"), 
     main="Fitbit wake detection",xlab="1-specificity",ylab="sensitivity",
     lwd=2,col="red")
legend(0.8,0.45,c("classic","new"),lty=c(1,1),lwd=c(3,3),col=c("black","red"))
abline(0,1,col="darkgray")

```

<br>

*Comments:*

- the ROC curves suggest that the SW update implies a slightly better accuracy compared to the "standard" classification.

The final step of EBE analyses is the computation of the **Cohen's kappa** coefficient and the **PABAK** (prevalence-adjusted bias-adjusted kappa). This is done using the epiR package.

<br>

```{r warning=FALSE,message=FALSE}

# Cohen's kappa
round(epi.kappa(as.table(as.matrix(confMatrix[,2:3])))$kappa$est,2)

# PABAK
round(epi.kappa(as.table(as.matrix(confMatrix[,2:3])))$pabak$est,2)

# bias index
round(epi.kappa(as.table(as.matrix(confMatrix[,2:3])))$bindex$est,2)

# prevalence index
round(epi.kappa(as.table(as.matrix(confMatrix[,2:3])))$pindex$est,2)

```

<br>

*Comments:*

- The computed kappa coefficient is .52 (moderate agreement) while the PABAK is .83 (almost perfect agreement). 

- The inconsistence is largely due to the higher prevalence of sleep epochs compared to wake epochs, as indicated by the prevalence index (-.81), which is much higher than the bias index (-.05), indicating the difference in sleep and wake scoring proportions between Fitbit and PSG.

<br>

### Function

<br>

Now we can create a function to automatize the procedure reported in the previous section.

<br>

```{r warning=FALSE,message=FALSE}

ebe_analysis <- function(data=NA,stage=10,stageLabel="wake",doPlot=TRUE){
  
  # DYCHOTOMIC ENCODING
  # .....................................................................
  
  d <- data
  
  # "classic" Fitbit dychotomous recoding
  d$classic.FB_EBE = NA
  d[d$Classic_FB==stage,"classic.FB_EBE"] = 1 # target stage = 1
  d[d$Classic_FB!=stage,"classic.FB_EBE"] = 0 # other stages = 0
  
  # "new" Fitbit dychotomous recoding
  d$new.FB_EBE = NA
  d[d$New_FB==stage,"new.FB_EBE"] = 1 # target stage = 1
  d[d$New_FB!=stage,"new.FB_EBE"] = 0 # other stages = 0

  # PSG dychotomous recoding
  d$PSG_EBE <- NA
  d[d$PSG==stage,"PSG_EBE"] = 1 # target stage = 1
  d[d$PSG!=stage,"PSG_EBE"] = 0 # other stages = 0
  
  # CONFUSION MATRICES
  # .....................................................................
  
  CM_classic <- data.frame(Fitbit=c("positive","negative"),
                           PSG_positive=c(nrow(d[d$classic.FB_EBE==1 & d$PSG_EBE==1,]), # true wake
                                          nrow(d[d$classic.FB_EBE==0 & d$PSG_EBE==1,])), # false sleep
                           PSG_negative=c(nrow(d[d$classic.FB_EBE==1 & d$PSG_EBE==0,]), # false wake
                                          nrow(d[d$classic.FB_EBE==0 & d$PSG_EBE==0,]))) # true sleep
  CM_new <- data.frame(Fitbit=c("positive","negative"),
                       PSG_positive=c(nrow(d[d$new.FB_EBE==1 & d$PSG_EBE==1,]), # true wake
                                      nrow(d[d$new.FB_EBE==0 & d$PSG_EBE==1,])), # false sleep
                       PSG_negative=c(nrow(d[d$new.FB_EBE==1 & d$PSG_EBE==0,]), # false wake
                                      nrow(d[d$new.FB_EBE==0 & d$PSG_EBE==0,]))) # true sleep
  
  # EBE MEASURES
  # .....................................................................
  
  # accuracy
  acc.classic <- round(100*(CM_classic[1,2]+CM_classic[2,3])/
                         (CM_classic[1,2]+CM_classic[2,2]+CM_classic[1,3]+CM_classic[2,3]),2)
  acc.new <- round(100*(CM_new[1,2]+CM_new[2,3])/
                     (CM_new[1,2]+CM_new[2,2]+CM_new[1,3]+CM_new[2,3]),2)
  
  # sensitivity
  sens.classic <- round(100*CM_classic[1,2]/(CM_classic[1,2]+CM_classic[2,2]),2)
  sens.new <- round(100*CM_new[1,2]/(CM_new[1,2]+CM_new[2,2]),2)
  
  # specificity
  spec.classic <- round(100*CM_classic[2,3]/(CM_classic[2,3]+CM_classic[1,3]),2)
  spec.new <- round(100*CM_new[2,3]/(CM_new[2,3]+CM_new[1,3]),2)
  
  # prevalence
  prev.classic <- round(100*(CM_classic[1,2]+CM_classic[2,2])/
                          (CM_classic[1,2]+CM_classic[2,2]+CM_classic[1,3]+CM_classic[2,3]),2)
  prev.new <- round(100*(CM_new[1,2]+CM_new[2,2])/
                      (CM_new[1,2]+CM_new[2,2]+CM_new[1,3]+CM_new[2,3]),2)
  
  # positive predictive value
  ppv.classic <- round(100*(sens.classic*prev.classic)/
                         (sens.classic*prev.classic + (1-spec.classic)*(1-prev.classic)),2)
  ppv.new <- round(100*(sens.new*prev.new)/(sens.new*prev.new + (1-spec.new)*(1-prev.new)),2)
  
  # negative predictive value
  npv.classic <- round(100*(spec.classic*(1-prev.classic))/
                         ((1-sens.classic)*prev.classic + spec.classic*(1-prev.classic)),2)
  npv.new <- round(100*(spec.new*(1-prev.new))/((1-sens.new)*prev.new + spec.new*(1-prev.new)),2)
  
  # KAPPA AND PABAK
  # .....................................................................
  
  # Cohen's kappa
  kappa.classic <- round(epiR::epi.kappa(as.table(as.matrix(CM_classic[1:2,2:3])))$kappa$est,2)
  kappa.new <- round(epiR::epi.kappa(as.table(as.matrix(CM_new[1:2,2:3])))$kappa$est,2)
  
  # PABAK
  pabak.classic <- round(epiR::epi.kappa(as.table(as.matrix(CM_classic[1:2,2:3])))$pabak$est,2)
  pabak.new <- round(epiR::epi.kappa(as.table(as.matrix(CM_new[1:2,2:3])))$pabak$est,2)

  # bias index
  bindex.classic <- round(epiR::epi.kappa(as.table(as.matrix(CM_classic[1:2,2:3])))$bindex$est,2)
  bindex.new <- round(epiR::epi.kappa(as.table(as.matrix(CM_new[1:2,2:3])))$bindex$est,2)

  # prevalence index
  pindex.classic <- round(epiR::epi.kappa(as.table(as.matrix(CM_classic[1:2,2:3])))$pindex$est,2)
  pindex.new <- round(epiR::epi.kappa(as.table(as.matrix(CM_new[1:2,2:3])))$pindex$est,2)

  # ALL IN ONE DATA.FRAME
  # .....................................................................
  
  results <- data.frame(measure=c("acc","sens","spec","PPV","NPV","kappa","PABAK","BIAS","PREV"),
                        FB_classic=c(acc.classic,sens.classic,spec.classic,ppv.classic,npv.classic,
                                     kappa.classic,pabak.classic,bindex.classic,pindex.classic),
                        FB_new=c(acc.new,sens.new,spec.new,ppv.new,npv.new,
                                 kappa.new,pabak.new,bindex.new,pindex.new))
  
  # RETURNING RESULTS AND ROC CURVES
  # .....................................................................
  
  if(doPlot){
    p <- plot(ROCR::performance(ROCR::prediction(d$classic.FB_EBE,d$PSG_EBE),"tpr","fpr"),lwd=2,
     main=paste(stageLabel,"- ROC curves"),xlab="1-specificity",ylab="sensitivity")
    par(new=TRUE)
    plot(ROCR::performance(ROCR::prediction(d$new.FB_EBE,d$PSG_EBE),"tpr","fpr"),lwd=2,col="red",xlab="",ylab="")
    legend(0.55,0.45,c("standard","SW"),lty=c(1,1),lwd=c(3,3),col=c("black","red"))
    abline(0,1,col="darkgray")
    res <- list(results,CM_classic,CM_new,p)
  } else {
    res <- list(results,CM_classic,CM_new)
  }
  
  return(structure(res))
  
}

```

<br>

Let's try our function.

<br>

```{r warning=FALSE,message=FALSE}

ebe_out <- ebe_analysis(data=ebe,stage=10,stageLabel="wake",doPlot=TRUE)
kable(ebe_out[[1]]) # EBE results
ebe_out[[2]] # classic system confusion matrix
ebe_out[[3]] # new system confusion matrix

```

<br>

### EBE Results

<br>

Here, we can use our function (see the previous sections) to generate the results of the EBE analysis.

As a first step, we recode PSG epochs scored as 1 (N1) and 2 (N2) as 2 (light), we generate the EBE table and we plot the ROC curves for any dychotomized condition (i.e., wake vs. non-wake, light vs. non-light, deep vs. non-deep, and REM vs. non-REM).

<br>

```{r warning=FALSE,message=FALSE}

ebe[ebe$PSG==1,"PSG"] <- 2 # recoding PSG light sleep epochs

par(mfrow=c(2,2))
ebe_results <- cbind(ebe_analysis(data=ebe,stage=10,stageLabel="wake",doPlot=TRUE)[[1]],
                     ebe_analysis(data=ebe,stage=2,stageLabel="light",doPlot=TRUE)[[1]][,2:3],
                     ebe_analysis(data=ebe,stage=3,stageLabel="deep",doPlot=TRUE)[[1]][,2:3],
                     ebe_analysis(data=ebe,stage=5,stageLabel="REM",doPlot=TRUE)[[1]][,2:3])

```

<br>

*Comments:*

- the ROC curves suggest that  **"new" classification system** show a slightly better accuracy only for **wake** and (very slightly) **light sleep** detection, whereas the accuracy in deep and REM sleep detection is exactly the same of the "classic" classification system.

<br>

```{r warning=FALSE,message=FALSE}

colnames(ebe_results) <- c("measure","wake_classic","wake_new","light_classic","light_new",
                           "deep_classic","deep_new","REM_classic","REM_new")
ebe_results

```

<br>

*Comments:*

- Overall, the best FC2 accuracy and agreement with PSG were observed for **wake detection**, in which both classification systems showed high specificity (here, the ability to correctly classify true sleep) but low sensitivity (here, the ability to correctly classify true wake). Coherently, the NPV was higher than the PPV.

- Similarly, relatively high accuracy and substantial agreement were observed for **deep** and **REM sleep** detection, in which the FC2 specificity was higher than its sensitivity, and NPV was slightly higher than PPV, suggesting a better FC2 ability to classify true negative as negative than to classify true positive as positive.

- **Light sleep** detection showed the lowest accuracy and agreement with PSG. Although sensitivity (here, the ability to correctly classify true light sleep) and PPV (percentage of PSG-derived light sleep epochs scored as light sleep also by the FC2) were slightly higher than those observed for other stages, both classification systems showed a lower specificity (here, the ability to classify epochs of true non-light sleep as non-light) and NPV (here, the rate of epochs scored as non-light by the PSG that were also scored as non-light by the FC2) in detecting light sleep compared to other stages.

- All stages but light sleep showed a low bias (i.e., differences in positive and negative scoring proportions between FC2 and PSG) and a relatively high negative prevalence, indicating higher rates of negative (e.g., sleep) compared to positive cases (e.g., wake). Consequently, the PABAK index was higher than the Cohen's kappa. The only exception was light sleep detection, where both bias and prevalence were relatively irrelevant.

- The **SW update** showed higher sensitivity and PPV for **wake detection** compared to the "standard" FC2 classification, suggesting an improvement in the FC2 ability to classify true wake. Coherently, the discrepancy between the Cohen's kappa and the PABAK for wake detection was lower for the SW-adjusted than for the "standard" classification, due to a slightly lower sleep prevalence in the former compared to the latter. Nevertheless, there was a relevant number of epochs (381, 17% of SW-adjusted wake epochs) where both PSG and the "standard" FC2 classification detected sleep, whereas the SW-adjusted classification detected wake, implicating a slightly lower specificity and NPV for the SW compared to the "standard" classification. In other words, the SW update showed an **higher false positives rate** and, consequently, a slightly lower accuracy and agreement with PSG.

Here, we can see the confusion matrices for the "standard" and the SW-adjusted classification, and the number of SW-derived false positive compared to the "standard" classification.

<br>

```{r warning=FALSE,message=FALSE}

# "standard" wake confusion matrix
ebe_analysis(data=ebe,stage=10,stageLabel="wake",doPlot=FALSE)[[2]] 

# SW-adjusted wake confusion matrix
ebe_analysis(data=ebe,stage=10,stageLabel="wake",doPlot=FALSE)[[3]] 

(N <- nrow(ebe[ebe$PSG!=10 & ebe$Classic_FB!=10 & ebe$New_FB==10,])) # n. of false positives for SW but not "standard"
100*N/nrow(ebe[ebe$New_FB==10,]) # percentage of false positive over SW-adjusted wake epochs

```

<br>

- No substantial differences between "standard" and SW classification were observed for light, deep and REM sleep detection, with only a slightly higher specificity for SW-adjusted light sleep detection.

<br>

```{r warning=FALSE,message=FALSE}

# "standard" light sleep confusion matrix
ebe_analysis(data=ebe,stage=2,stageLabel="wake",doPlot=FALSE)[[2]] 

# SW-adjusted light sleep confusion matrix
ebe_analysis(data=ebe,stage=2,stageLabel="wake",doPlot=FALSE)[[3]]

# "standard" deep sleep confusion matrix
ebe_analysis(data=ebe,stage=3,stageLabel="wake",doPlot=FALSE)[[2]] 

# SW-adjusted deep sleep confusion matrix
ebe_analysis(data=ebe,stage=3,stageLabel="wake",doPlot=FALSE)[[3]]

# "standard" REM sleep confusion matrix
ebe_analysis(data=ebe,stage=5,stageLabel="wake",doPlot=FALSE)[[2]] 

# SW-adjusted REM sleep confusion matrix
ebe_analysis(data=ebe,stage=5,stageLabel="wake",doPlot=FALSE)[[3]]

```

<br>

*Conclusions:*

The SW update improved the FC2 sensitivity to wake but it led to higher false positive rates in wake detection. Consquently, the "standard" classification system was considered for the following analyses.

<br>

### PLOTS FOR MANUSCRIPT

<br>

```{r warning=FALSE,message=FALSE,out.height='100%'}

grid.arrange(ba_analysis(sleep.classic$TST_PSG,sleep.classic$TST_Fb,ylim=c(-80,50),
                        return.data="plot",message=FALSE,doPlot=FALSE,title="FC2 STANDARD"),
             ba_analysis(sleep.new$TST_PSG,sleep.new$TST_Fb,ylim=c(-80,50),
                        return.data="plot",message=FALSE,doPlot=FALSE,title="FC2 SHORT WAKES"),
             ba_analysis(sleep.classic$WASO_PSG,sleep.classic$WASO_Fb,measure="WASO",ylim=c(-30,60),
                        return.data="plot",message=FALSE,doPlot=FALSE),
             ba_analysis(sleep.new$WASO_PSG,sleep.new$WASO_Fb,measure="WASO",ylim=c(-30,60),
                        return.data="plot",message=FALSE,doPlot=FALSE),
             ba_analysis(sleep.classic$SE_PSG,sleep.classic$SE_Fb,measure="SE",ylim=c(-20,15),
                        return.data="plot",message=FALSE,doPlot=FALSE),
             ba_analysis(sleep.new$SE_PSG,sleep.new$SE_Fb,measure="SE",ylim=c(-20,15),
                        return.data="plot",message=FALSE,doPlot=FALSE),
             nrow=3) 

```

<br>

```{r warning=FALSE,message=FALSE,out.width='100%'}

grid.arrange(ba_analysis(sleep.classic$Light_PSG,sleep.classic$Light_Fb,measure="Light",ylim=c(0,45),
                        return.data="plot",message=FALSE,doPlot=FALSE,title="FC2 STANDARD"),
             ba_analysis(sleep.new$Light_PSG,sleep.new$Light_Fb,measure="Light",ylim=c(0,45),
                        return.data="plot",message=FALSE,doPlot=FALSE,title="FC2 SHORT WAKES"),
             ba_analysis(sleep.classic$Deep_PSG,sleep.classic$Deep_Fb,measure="Deep",ylim=c(-100,100),
                        return.data="plot",message=FALSE,doPlot=FALSE),
             ba_analysis(sleep.new$Deep_PSG,sleep.new$Deep_Fb,measure="Deep",ylim=c(-100,100),
                        return.data="plot",message=FALSE,doPlot=FALSE),
             ba_analysis(sleep.classic$REM_PSG,sleep.classic$REM_Fb,measure="REM",ylim=c(-75,75),
                        return.data="plot",message=FALSE,doPlot=FALSE),
             ba_analysis(sleep.new$REM_PSG,sleep.new$REM_Fb,measure="REM",ylim=c(-75,75),
                        return.data="plot",message=FALSE,doPlot=FALSE),
             nrow=3) 

```

<br>

## INFLUENTIAL ANALYSIS {.tabset .tabset-fade .tabset-pills}

<br>

As our sample is very small, and small differences were found between the FC2 "standard" classification and the SW update, we are interested in checking if these differeces are due to single cases showing extreme values in PSG- and/or FC2-derived measures.

In particular, we are interested in Wake and "light" sleep measurement **sensitivity**, in the number of **false positives** showed in wake detection by the two classification systems, and on the **bias observed for TST**.

Here, we evaluate the presence of extreme cases by computing each of these measures iteratively, by removing each night one by one.

<br>

### PIPELINE

<br>

As a first step, we create a new variable in the EBE dataset to identify participant-night couples.

<br>

```{r warning=FALSE,message=FALSE,out.width='100%'}

ebe$idNight <- as.factor(paste(ebe$id,ebe$night))
levels(ebe$idNight)

```

<br>

Such an identifying variable is already included in the sleep datasets (id)

<br>

```{r warning=FALSE,message=FALSE,out.width='100%'}

levels(as.factor(sleep.classic$Subject))
levels(as.factor(sleep.new$Subject))

```

<br>

We start by computing the **false positives rate** and the **sensitivity** for wake detection. The former will be computed as the percentage of false positives over the total number of cases classified as wake by the FC2. For each participant-night couple, the two measures are computed by removing that case.

<br>

```{r warning=FALSE,message=FALSE,out.width='100%'}

# "standard" and SW sensitivity, and SW false positives for the whole sample
influentEBE <- data.frame(id="all",
                          sens_classic=ebe_analysis(data=ebe,stage=10,
                                                    stageLabel="wake",doPlot=FALSE)[[1]][2,2],
                          sens_new=ebe_analysis(data=ebe,stage=10,
                                                stageLabel="wake",doPlot=FALSE)[[1]][2,3],
                          falsePos=ebe_analysis(data=ebe,stage=10,
                                                stageLabel="wake",doPlot=FALSE)[[3]][1,3]/
                            (ebe_analysis(data=ebe,stage=10,
                                                stageLabel="wake",doPlot=FALSE)[[3]][1,2]+
                               ebe_analysis(data=ebe,stage=10,
                                                stageLabel="wake",doPlot=FALSE)[[3]][1,3]))

IDs <- levels(ebe$idNight)
for(ID in IDs){
  out <- ebe[ebe$idNight!=ID,]
  influentEBE <- rbind(influentEBE,
                       data.frame(id=ID,
                                  sens_classic=ebe_analysis(data=out,stage=10,
                                                            stageLabel="wake",doPlot=FALSE)[[1]][2,2],
                                  sens_new=ebe_analysis(data=out,stage=10,
                                                        stageLabel="wake",doPlot=FALSE)[[1]][2,3],
                                  falsePos=ebe_analysis(data=out,stage=10,
                                                        stageLabel="wake",doPlot=FALSE)[[3]][1,3]/
                                    (ebe_analysis(data=out,stage=10,
                                                        stageLabel="wake",doPlot=FALSE)[[3]][1,2]+
                                       ebe_analysis(data=out,stage=10,
                                                        stageLabel="wake",doPlot=FALSE)[[3]][1,3])))
}
influentEBE

```

<br>

Then, we apply the same procedure to compute the TST bias.

<br>

```{r warning=FALSE,message=FALSE,out.width='100%'}

# "standard" and SW sensitivity, and SW false positives for the whole sample
influentTST <- data.frame(id="all",
                          TSTbias_classic=as.numeric(substr(ba_analysis(sleep.classic$TST_PSG,
                                                                        sleep.classic$TST_Fb,
                                                                        measure="TST",doPlot=FALSE,
                                                                        message=FALSE)[1,2],1,6)),
                          TSTbias_new=as.numeric(substr(ba_analysis(sleep.new$TST_PSG,
                                                                    sleep.new$TST_Fb,
                                                                    measure="TST",doPlot=FALSE,
                                                                    message=FALSE)[1,2],1,6)))

IDs <- levels(as.factor(sleep.classic$Subject))
for(ID in IDs){
  out_classic <- sleep.classic[sleep.classic$Subject!=ID,]
  out_new <- sleep.new[sleep.new$Subject!=ID,]
  influentTST <- rbind(influentTST,
                       data.frame(id=ID,
                                  TSTbias_classic=as.numeric(substr(ba_analysis(out_classic$TST_PSG,
                                                                                out_classic$TST_Fb,
                                                                                measure="TST",doPlot=FALSE,
                                                                                message=FALSE)[1,2],1,6)),
                                  TSTbias_new=as.numeric(substr(ba_analysis(out_new$TST_PSG,
                                                                            out_new$TST_Fb,
                                                                            measure="TST",doPlot=FALSE,
                                                                            message=FALSE)[1,2],1,6))))
}
influentTST

```

<br>

### RESULTS  {.tabset .tabset-fade .tabset-pills}

<br>

Let's plot the results. In each plot, the value obtained on the whole sample is represented by the blue dot, whereas all other cases are represented by the black dots. Identifying labels are reported only for extreme cases.

<br>

#### EBE

<br>

```{r warning=FALSE,message=FALSE}

ggplot(influentEBE,aes(x=id,y=sens_classic))+geom_point()+ggtitle("Sensitivity of FC2 'standard'")+
  geom_point(data=influentEBE[influentEBE$id=="all",],colour="blue",size=5)+
  geom_text(data=influentEBE[influentEBE$sens_classic<43.5|influentEBE$sens_classic>45.5,],
            aes(label=id),nudge_y = -.2,size=3)+
  theme(axis.text.x = element_blank())

ggplot(influentEBE,aes(x=id,y=sens_new))+geom_point()+ggtitle("Sensitivity of FC2 'new'")+
  geom_point(data=influentEBE[influentEBE$id=="all",],colour="blue",size=5)+
  geom_text(data=influentEBE[influentEBE$sens_new<55|influentEBE$sens_new>57.5,],
            aes(label=id),nudge_y = -.2,size=3)+
  theme(axis.text.x = element_blank())

ggplot(influentEBE,aes(x=id,y=falsePos))+geom_point()+ggtitle("False positives wake of FC2 'new'")+
  geom_point(data=influentEBE[influentEBE$id=="all",],colour="blue",size=5)+
  geom_text(data=influentEBE[influentEBE$falsePos<.34|influentEBE$falsePos>.36,],
            aes(label=id),nudge_y = -.002,size=3)+
  theme(axis.text.x = element_blank())

```

<br>

#### TST BIAS

<br>

```{r warning=FALSE,message=FALSE}

ggplot(influentTST,aes(x=id,y=TSTbias_classic))+geom_point()+ggtitle("FC2 'standard' bias in TST")+
  geom_point(data=influentTST[influentTST$id=="all",],colour="blue",size=5)+
  geom_text(data=influentTST[influentTST$TSTbias_classic<(-19.5)|influentTST$TSTbias_classic>(-17.5),],
            aes(label=id),nudge_y = -.2,size=3)+
  theme(axis.text.x = element_blank())

ggplot(influentTST,aes(x=id,y=TSTbias_new))+geom_point()+ggtitle("FC2 'short wakes' bias in TST")+
  geom_point(data=influentTST[influentTST$id=="all",],colour="blue",size=5)+
  geom_text(data=influentTST[influentTST$TSTbias_new<(-7)|influentTST$TSTbias_new>(-5),],
            aes(label=id),nudge_y = -.2,size=3)+
  theme(axis.text.x = element_blank())

```

<br>

### CONCLUSIONS 

<br>

Neither the EBE analysis nor the computation of the TST bias show extremely influential cases in the variables of interest. Only the removal of few cases showed to be slightly influential on the computed values:

- night 1 for AA007 and AA040 are associated to a sensitivity increase of 2.5% in both the "standard" FC2 classification and the SW update, and to a SW-derived false positives rate decrease of 2%. 

- night 1 for AA039 and night 2 for AA006 are associated to a sensitivity decrease of 1.5% in both the "standard" FC2 classification and the SW update.

- night 2 for AA023 and AA040 are associated to a SW-derived false positive rate increase of 2%.

- night 1 for AA039 and night 2 for AA006 are associated to a TST bias decrease of 2 minutes.

- night 2 for AA040 is associated to a TST bias increase of 1 minute.

<br>

In conclusion, althoug some cases (night 2 for AA006) seem to influence the results more strongly than other cases, the changes in the computed measures are relatively small compared to differences between "standard" FC2 and WS-adjusted classifications, and thus they are approximately irrelevant for our results. Indeed, in all cases the points are quite sparese and centered on the value found on the whole sample. 

<br>